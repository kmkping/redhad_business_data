{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import StratifiedKFold,KFold,train_test_split\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_dimen(dataset,column,toreplace):\n",
    "    for index,i in dataset[column].duplicated(keep=False).iteritems():\n",
    "        if i==False:\n",
    "            dataset.set_value(index,column,toreplace)\n",
    "    return dataset\n",
    "    \n",
    "def act_data_treatment(dsname):\n",
    "    dataset = dsname\n",
    "    \n",
    "    for col in list(dataset.columns):\n",
    "        if col not in ['people_id', 'activity_id', 'date', 'char_38', 'outcome']:\n",
    "            if dataset[col].dtype == 'object':\n",
    "                dataset[col].fillna('type 0', inplace=True)\n",
    "                dataset[col] = dataset[col].apply(lambda x: x.split(' ')[1]).astype(np.int32)\n",
    "            elif dataset[col].dtype == 'bool':\n",
    "                dataset[col] = dataset[col].astype(np.int8)\n",
    "    \n",
    "    #dataset['year'] = dataset['date'].dt.year\n",
    "    #dataset['month'] = dataset['date'].dt.month\n",
    "    #dataset['day'] = dataset['date'].dt.day\n",
    "    #dataset['isweekend'] = (dataset['date'].dt.weekday >= 5).astype(int)\n",
    "    dataset = dataset.drop('date', axis = 1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (2197291, 14)\n",
      "Test data shape: (498687, 13)\n",
      "People data shape: (189118, 41)\n"
     ]
    }
   ],
   "source": [
    "act_train_data = pd.read_csv(\"input/act_train.csv\",dtype={'people_id': np.str, 'activity_id': np.str, 'outcome': np.int8}, parse_dates=['date'])\n",
    "act_test_data  = pd.read_csv(\"input/act_test.csv\", dtype={'people_id': np.str, 'activity_id': np.str}, parse_dates=['date'])\n",
    "people_data    = pd.read_csv(\"input/people.csv\", dtype={'people_id': np.str, 'activity_id': np.str, 'char_38': np.int32}, parse_dates=['date'])\n",
    "\n",
    "act_train_data=act_train_data.drop('char_10',axis=1)\n",
    "act_test_data=act_test_data.drop('char_10',axis=1)\n",
    "\n",
    "print(\"Train data shape: \" + format(act_train_data.shape))\n",
    "print(\"Test data shape: \" + format(act_test_data.shape))\n",
    "print(\"People data shape: \" + format(people_data.shape))\n",
    "\n",
    "act_train_data  = act_data_treatment(act_train_data)\n",
    "act_test_data   = act_data_treatment(act_test_data)\n",
    "people_data = act_data_treatment(people_data)\n",
    "\n",
    "train = act_train_data.merge(people_data, on='people_id', how='left', left_index=True)\n",
    "test  = act_test_data.merge(people_data, on='people_id', how='left', left_index=True)\n",
    "\n",
    "del act_train_data\n",
    "del act_test_data\n",
    "del people_data\n",
    "\n",
    "train=train.sort_values(['people_id'], ascending=[1])\n",
    "test=test.sort_values(['people_id'], ascending=[1])\n",
    "\n",
    "train_columns = train.columns.values\n",
    "test_columns = test.columns.values\n",
    "features = list(set(train_columns) & set(test_columns))\n",
    "\n",
    "train.fillna('NA', inplace=True)\n",
    "test.fillna('NA', inplace=True)\n",
    "\n",
    "y = train.outcome\n",
    "train=train.drop('outcome',axis=1)\n",
    "\n",
    "whole=pd.concat([train,test],ignore_index=True)\n",
    "categorical=['group_1','activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x','char_6_x','char_7_x','char_8_x','char_9_x','char_2_y','char_3_y','char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']\n",
    "for category in categorical:\n",
    "    whole=reduce_dimen(whole,category,9999999)\n",
    "    \n",
    "X=whole[:len(train)]\n",
    "X_test=whole[len(train):]\n",
    "\n",
    "del train\n",
    "del whole\n",
    "    \n",
    "X=X.sort_values(['people_id'], ascending=[1])\n",
    "\n",
    "X = X[features].drop(['people_id', 'activity_id', 'char_1_y'], axis = 1)\n",
    "X_test = X_test[features].drop(['people_id', 'activity_id', 'char_1_y'], axis = 1)\n",
    "\n",
    "#list categorical features and label them\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical=['group_1','activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x','char_6_x','char_7_x','char_8_x','char_9_x','char_2_y','char_3_y','char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']\n",
    "not_categorical=[]\n",
    "for category in X.columns:\n",
    "    if category not in categorical:\n",
    "        not_categorical.append(category)\n",
    "    else:\n",
    "        temp = pd.concat([X[category],X_test[category]])\n",
    "        le = LabelEncoder()\n",
    "        le.fit(temp.values)\n",
    "        X[category] = le.transform(X[category].values)\n",
    "        X_test[category] = le.transform(X_test[category].values) \n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc=enc.fit(pd.concat([X[categorical],X_test[categorical]]))\n",
    "X_cat_sparse=enc.transform(X[categorical])\n",
    "X_test_cat_sparse=enc.transform(X_test[categorical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2197291, 29), (2197291, 19), (498687, 29), (498687, 19))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[not_categorical].shape, X[categorical].shape, X_test[not_categorical].shape, X_test[categorical].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (2197291, 31262)\n",
      "Test data: (498687, 31262)\n",
      "###########\n",
      "One Hot enconded Test Dataset Script\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_sparse=hstack((X[not_categorical], X_cat_sparse))\n",
    "X_test_sparse=hstack((X_test[not_categorical], X_test_cat_sparse))\n",
    "\n",
    "print(\"Training data: \" + format(X_sparse.shape))\n",
    "print(\"Test data: \" + format(X_test_sparse.shape))\n",
    "print(\"###########\")\n",
    "print(\"One Hot enconded Test Dataset Script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_sparse,label=y)\n",
    "dtest = xgb.DMatrix(X_test_sparse)\n",
    "\n",
    "param = {'max_depth':10, 'eta':0.02, 'silent':0, 'objective':'binary:logistic' }\n",
    "#param['nthread'] = 2\n",
    "param['eval_metric'] = 'auc'\n",
    "param['subsample'] = 0.7\n",
    "param['colsample_bytree']= 0.7\n",
    "param['min_child_weight'] = 0\n",
    "param['booster'] = \"gblinear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_sparse\n",
    "del X_test_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.887823\n",
      "Will train until train-auc hasn't improved in 10 rounds.\n",
      "[10]\ttrain-auc:0.961044\n",
      "[20]\ttrain-auc:0.986776\n",
      "[30]\ttrain-auc:0.992257\n",
      "[40]\ttrain-auc:0.994342\n",
      "[50]\ttrain-auc:0.995419\n",
      "[60]\ttrain-auc:0.996045\n",
      "[70]\ttrain-auc:0.996437\n",
      "[80]\ttrain-auc:0.996694\n",
      "[90]\ttrain-auc:0.996863\n",
      "[100]\ttrain-auc:0.996972\n",
      "[110]\ttrain-auc:0.997044\n",
      "[120]\ttrain-auc:0.997093\n",
      "[130]\ttrain-auc:0.997128\n",
      "[140]\ttrain-auc:0.997153\n",
      "[150]\ttrain-auc:0.997172\n",
      "[160]\ttrain-auc:0.997185\n",
      "[170]\ttrain-auc:0.997195\n",
      "[180]\ttrain-auc:0.997202\n",
      "[190]\ttrain-auc:0.997207\n",
      "[200]\ttrain-auc:0.997211\n",
      "[210]\ttrain-auc:0.997214\n",
      "[220]\ttrain-auc:0.997216\n",
      "[230]\ttrain-auc:0.997218\n",
      "[240]\ttrain-auc:0.99722\n",
      "[250]\ttrain-auc:0.997221\n",
      "[260]\ttrain-auc:0.997223\n",
      "[270]\ttrain-auc:0.997224\n",
      "[280]\ttrain-auc:0.997225\n",
      "[290]\ttrain-auc:0.997226\n",
      "Stopping. Best iteration:\n",
      "[284]\ttrain-auc:0.997226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(120)\n",
    "evals  = [(dtrain,'train')]\n",
    "num_round = 305\n",
    "bst = xgb.train(param, dtrain, num_round, evals, early_stopping_rounds=10, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "b88c26cc-f42c-4e0e-818d-b89002d87a0e"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: without_leak.csv (deflated 77%)\n"
     ]
    }
   ],
   "source": [
    "ypred = bst.predict(dtest)\n",
    "output = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred })\n",
    "output.head()\n",
    "output.to_csv('without_leak.csv', index = False)\n",
    "!zip subb.zip without_leak.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
